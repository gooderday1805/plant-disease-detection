{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Dataset**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-08T12:06:31.686998Z",
     "iopub.status.busy": "2025-05-08T12:06:31.686746Z",
     "iopub.status.idle": "2025-05-08T12:07:23.181955Z",
     "shell.execute_reply": "2025-05-08T12:07:23.180882Z",
     "shell.execute_reply.started": "2025-05-08T12:06:31.686969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/your_dataset /kaggle/working/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:07:38.532360Z",
     "iopub.status.busy": "2025-05-08T12:07:38.531700Z",
     "iopub.status.idle": "2025-05-08T12:07:43.249617Z",
     "shell.execute_reply": "2025-05-08T12:07:43.248876Z",
     "shell.execute_reply.started": "2025-05-08T12:07:38.532329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.16)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading needed libraries or frameworks**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:07:46.915305Z",
     "iopub.status.busy": "2025-05-08T12:07:46.915034Z",
     "iopub.status.idle": "2025-05-08T12:07:55.892751Z",
     "shell.execute_reply": "2025-05-08T12:07:55.891783Z",
     "shell.execute_reply.started": "2025-05-08T12:07:46.915282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage import color, graph\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.nn import BatchNorm, LayerNorm, PairNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data visualization**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:47.933416Z",
     "iopub.status.busy": "2025-05-08T12:59:47.932707Z",
     "iopub.status.idle": "2025-05-08T12:59:47.941601Z",
     "shell.execute_reply": "2025-05-08T12:59:47.941025Z",
     "shell.execute_reply.started": "2025-05-08T12:59:47.933389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_sample_dataset(root_dir, num_images=5):\n",
    "    \"\"\"Display sample images from dataset\"\"\"\n",
    "    plant_types = os.listdir(root_dir)\n",
    "    for plant in plant_types:\n",
    "        plant_path = os.path.join(root_dir, plant)\n",
    "        if not os.path.isdir(plant_path):\n",
    "            continue\n",
    "        print(f\"\\nShowing samples from plant: {plant}\")\n",
    "        disease_types = os.listdir(plant_path)\n",
    "        for disease in disease_types:\n",
    "            disease_path = os.path.join(plant_path, disease)\n",
    "            if not os.path.isdir(disease_path):\n",
    "                continue\n",
    "            img_files = [f for f in os.listdir(disease_path) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "            samples = random.sample(img_files, min(len(img_files), num_images))\n",
    "            print(f\"Disease: {disease} ({len(samples)} samples)\")\n",
    "            for fname in samples:\n",
    "                img_path = os.path.join(disease_path, fname)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read image {img_path}\")\n",
    "                    continue\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                plt.figure(figsize=(4, 4))\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"{plant} - {disease}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dataset\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:47.947341Z",
     "iopub.status.busy": "2025-05-08T12:59:47.946756Z",
     "iopub.status.idle": "2025-05-08T12:59:47.955369Z",
     "shell.execute_reply": "2025-05-08T12:59:47.954714Z",
     "shell.execute_reply.started": "2025-05-08T12:59:47.947321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(root_dir, output_dir, train_ratio=0.8, test_ratio = 0.2, seed=42):\n",
    "    \"\"\"\n",
    "    Split dataset into train and test sets with stratification\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for split in ['train', 'test']:\n",
    "        os.makedirs(os.path.join(output_dir, split), exist_ok=True)\n",
    "    \n",
    "    classes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "    \n",
    "    for cls in classes:\n",
    "        cls_folder = os.path.join(root_dir, cls)\n",
    "        \n",
    "        # Create class directories in each split\n",
    "        for split in ['train', 'test']:\n",
    "            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n",
    "        \n",
    "        # Get images\n",
    "        images = [f for f in os.listdir(cls_folder) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        # Calculate split indices\n",
    "        train_idx = int(len(images) * train_ratio)\n",
    "        test_idx = train_idx + int(len(images) * test_ratio)\n",
    "        \n",
    "        # Split images\n",
    "        train_imgs = images[:train_idx]\n",
    "        test_imgs = images[train_idx:]\n",
    "        \n",
    "        # Copy images to respective folders\n",
    "        for split, img_list in zip(['train', 'test'], [train_imgs, test_imgs]):\n",
    "            for img_name in img_list:\n",
    "                src = os.path.join(cls_folder, img_name)\n",
    "                dst = os.path.join(output_dir, split, cls, img_name)\n",
    "                shutil.copy2(src, dst)\n",
    "                \n",
    "    # Print split statistics\n",
    "    train_count = sum(len(os.listdir(os.path.join(output_dir, 'train', cls))) for cls in classes)\n",
    "    test_count = sum(len(os.listdir(os.path.join(output_dir, 'test', cls))) for cls in classes)\n",
    "    total = train_count + test_count\n",
    "    \n",
    "    print(f\"✅ Dataset split completed:\")\n",
    "    print(f\"  Train: {train_count} images ({train_count/total*100:.1f}%)\")\n",
    "    print(f\"  Test: {test_count} images ({test_count/total*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SLIC - Simple Linear Iterative Clustering**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:47.959318Z",
     "iopub.status.busy": "2025-05-08T12:59:47.959107Z",
     "iopub.status.idle": "2025-05-08T12:59:47.963546Z",
     "shell.execute_reply": "2025-05-08T12:59:47.962938Z",
     "shell.execute_reply.started": "2025-05-08T12:59:47.959302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_segments_using_slic(image, num_segments=50, compactness=15):\n",
    "    \"\"\"\n",
    "    Extract super-pixel segments using SLIC algorithm with improved parameters\n",
    "    for leaf disease classification\n",
    "    \"\"\"\n",
    "    # Convert to LAB color space for better segmentation of leaf patterns\n",
    "    img_lab = color.rgb2lab(image)\n",
    "    \n",
    "    # Apply SLIC with adjusted parameters for capturing disease patterns\n",
    "    segments = slic(\n",
    "        img_lab, \n",
    "        n_segments=num_segments, \n",
    "        compactness=compactness, \n",
    "        sigma=2, \n",
    "        start_label=0,\n",
    "        channel_axis=2\n",
    "    )\n",
    "    \n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enhanced feature extraction**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:47.985727Z",
     "iopub.status.busy": "2025-05-08T12:59:47.985258Z",
     "iopub.status.idle": "2025-05-08T12:59:47.991973Z",
     "shell.execute_reply": "2025-05-08T12:59:47.991184Z",
     "shell.execute_reply.started": "2025-05-08T12:59:47.985704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def obtain_enhanced_node_features(image, segments):\n",
    "    \"\"\"\n",
    "    Enhanced feature extraction for each segment including color and texture\n",
    "    \"\"\"\n",
    "    node_features = []\n",
    "    \n",
    "    # Convert to multiple color spaces for richer features\n",
    "    img_hsv = cv2.cvtColor(\n",
    "        (image * 255).astype(np.uint8), \n",
    "        cv2.COLOR_RGB2HSV\n",
    "    ).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Get maximum segment ID\n",
    "    max_segment_id = segments.max()\n",
    "    \n",
    "    for i in range(max_segment_id + 1):\n",
    "        mask = segments == i\n",
    "        if np.any(mask):  # Make sure segment is not empty\n",
    "            # Extract RGB features\n",
    "            rgb_features = image[mask].mean(axis=0)  # Shape: (3,)\n",
    "            \n",
    "            # Extract HSV features\n",
    "            hsv_features = img_hsv[mask].mean(axis=0)  # Shape: (3,)\n",
    "            \n",
    "            # Extract simple texture features (standard deviation of colors)\n",
    "            texture_rgb = np.std(image[mask], axis=0) if mask.sum() > 1 else np.zeros(3)\n",
    "            \n",
    "            # Calculate segment size (normalized by image size)\n",
    "            segment_size = mask.sum() / (image.shape[0] * image.shape[1])\n",
    "            \n",
    "            # Combine features\n",
    "            features = np.concatenate([\n",
    "                rgb_features,          # RGB mean (3)\n",
    "                hsv_features,          # HSV mean (3)\n",
    "                texture_rgb,           # RGB std (3)\n",
    "                [segment_size]         # Size (1)\n",
    "            ])\n",
    "            \n",
    "            node_features.append(features)\n",
    "        else:\n",
    "            # Default features for empty segments\n",
    "            node_features.append(np.zeros(10))\n",
    "    \n",
    "    return np.array(node_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG -  Region Adjacency Graph**\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:48.018842Z",
     "iopub.status.busy": "2025-05-08T12:59:48.018303Z",
     "iopub.status.idle": "2025-05-08T12:59:48.024098Z",
     "shell.execute_reply": "2025-05-08T12:59:48.023338Z",
     "shell.execute_reply.started": "2025-05-08T12:59:48.018819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def construct_region_adjacency_graph(image, segments):\n",
    "    \"\"\"\n",
    "    Construct region adjacency graph from segments with improved edge weighting\n",
    "    \"\"\"\n",
    "    # Create region adjacency graph - this now uses edge weights based on color difference\n",
    "    rag = graph.rag_mean_color(image, segments)\n",
    "    \n",
    "    # Construct edge index and edge attributes for PyG\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    for n1, n2, data in rag.edges(data=True):\n",
    "        # Add edge in both directions (undirected graph)\n",
    "        edge_index.append([n1, n2])\n",
    "        edge_index.append([n2, n1])\n",
    "        \n",
    "        # Extract edge weight (color similarity)\n",
    "        weight = data.get('weight', 1.0)\n",
    "        \n",
    "        # Add normalized weight as edge attribute\n",
    "        norm_weight = np.exp(-weight / 10.0)  # Exponential decay for large color differences\n",
    "        edge_attr.append([norm_weight])\n",
    "        edge_attr.append([norm_weight])\n",
    "    \n",
    "    # Handle empty edge case\n",
    "    if not edge_index:\n",
    "        edge_index = [[0, 0], [0, 0]]  # Self-loop as fallback\n",
    "        edge_attr = [[1.0], [1.0]]\n",
    "        \n",
    "    return np.array(edge_index).T, np.array(edge_attr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image to graph SLIC + CLAHE + RAG **\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:48.064288Z",
     "iopub.status.busy": "2025-05-08T12:59:48.063516Z",
     "iopub.status.idle": "2025-05-08T12:59:48.070320Z",
     "shell.execute_reply": "2025-05-08T12:59:48.069614Z",
     "shell.execute_reply.started": "2025-05-08T12:59:48.064262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_image_to_graph(image_path, num_segments=50, compactness=15):\n",
    "    \"\"\"\n",
    "    Convert an image to a graph representation using enhanced SLIC segmentation\n",
    "    with richer node features and edge attributes\n",
    "    \"\"\"\n",
    "    # 1. Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    \n",
    "    # 2. Preprocess image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 3. Apply CLAHE for contrast enhancement\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    lab_planes = list(cv2.split(lab))  # Convert to list to allow assignment\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    lab = cv2.merge(lab_planes)\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    \n",
    "    # 4. Resize image\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    \n",
    "    # 5. Normalize the image\n",
    "    img = img / 255.0\n",
    "    \n",
    "    # 6. Extract segments using SLIC\n",
    "    segments = extract_segments_using_slic(img, num_segments, compactness)\n",
    "    \n",
    "    # 7. Obtain enhanced node features\n",
    "    node_features = obtain_enhanced_node_features(img, segments)\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    # 8. Construct region adjacency graph with edge attributes\n",
    "    edge_index, edge_attr = construct_region_adjacency_graph(img, segments)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "    return node_features, edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store RAG features in pickle files for training**\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:48.071805Z",
     "iopub.status.busy": "2025-05-08T12:59:48.071592Z",
     "iopub.status.idle": "2025-05-08T12:59:48.079709Z",
     "shell.execute_reply": "2025-05-08T12:59:48.078891Z",
     "shell.execute_reply.started": "2025-05-08T12:59:48.071789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_precomputed_graphs(root_dir, output_dir, num_segments=50, compactness=15):\n",
    "    \"\"\"Precompute and save enhanced graph representations of all images\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.isdir(os.path.join(root_dir, \"train\")) and os.path.isdir(os.path.join(root_dir, \"test\")):\n",
    "        # Dataset is already split into train and test\n",
    "        splits = [\"train\", \"test\"]\n",
    "    else:\n",
    "        # Dataset is not split yet\n",
    "        splits = [\"\"]\n",
    "    \n",
    "    for split in splits:\n",
    "        split_dir = os.path.join(root_dir, split) if split else root_dir\n",
    "        split_output_dir = os.path.join(output_dir, split) if split else output_dir\n",
    "        os.makedirs(split_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Process each class\n",
    "        classes = [d for d in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, d))]\n",
    "        \n",
    "        for cls in classes:\n",
    "            cls_dir = os.path.join(split_dir, cls)\n",
    "            cls_output_dir = os.path.join(split_output_dir, cls)\n",
    "            os.makedirs(cls_output_dir, exist_ok=True)\n",
    "            \n",
    "            # Get list of images\n",
    "            img_files = [f for f in os.listdir(cls_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            print(f\"Processing {len(img_files)} images from {cls} ({split})\")\n",
    "            \n",
    "            for img_file in tqdm(img_files):\n",
    "                img_path = os.path.join(cls_dir, img_file)\n",
    "                graph_file = os.path.join(cls_output_dir, f\"{os.path.splitext(img_file)[0]}.pkl\")\n",
    "                \n",
    "                try:\n",
    "                    # Convert image to graph with enhanced features\n",
    "                    x, edge_index, edge_attr = preprocessing_image_to_graph(img_path, num_segments, compactness)\n",
    "                    \n",
    "                    # Save the graph\n",
    "                    with open(graph_file, 'wb') as f:\n",
    "                        pickle.dump((x, edge_index, edge_attr), f)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    print(f\"✅ Enhanced precomputed graphs have been saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edge augmentations**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:07:22.935858Z",
     "iopub.status.busy": "2025-05-08T18:07:22.935087Z",
     "iopub.status.idle": "2025-05-08T18:07:22.945354Z",
     "shell.execute_reply": "2025-05-08T18:07:22.944768Z",
     "shell.execute_reply.started": "2025-05-08T18:07:22.935832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def edge_augmentation(data, p_add=0.1, p_remove=0.1):\n",
    "    \"\"\"\n",
    "    Edge augmentation based on Algorithm 1:\n",
    "    - With probability p_add, add random edges\n",
    "    - With probability p_remove, remove random edges\n",
    "    \n",
    "    Args:\n",
    "        data: PyG Data object\n",
    "        p_add: Probability of adding edges\n",
    "        p_remove: Probability of removing edges\n",
    "    \n",
    "    Returns:\n",
    "        Augmented PyG Data object\n",
    "    \"\"\"\n",
    "    # Initialize: E_aug ← E\n",
    "    edge_index = data.edge_index.clone()\n",
    "    edge_attr = data.edge_attr.clone() if hasattr(data, 'edge_attr') else None\n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # If random probability < p_add then add edges\n",
    "    if random.random() < p_add and num_nodes > 1:\n",
    "        # Generate multiple random edges (more efficient)\n",
    "        num_edges_to_add = max(1, int(edge_index.size(1) * 0.05))  # Add 5% more edges\n",
    "        for _ in range(num_edges_to_add):\n",
    "            # Generate random edge\n",
    "            u = random.randint(0, num_nodes - 1)\n",
    "            v = random.randint(0, num_nodes - 1)\n",
    "            \n",
    "            # Avoid self-loops\n",
    "            if u != v:\n",
    "                # Add edge: E_aug ← E_aug ∪ e_new\n",
    "                new_edge = torch.tensor([[u, v], [v, u]], dtype=torch.long, device=edge_index.device)\n",
    "                edge_index = torch.cat([edge_index, new_edge.t()], dim=1)\n",
    "                \n",
    "                # Add edge attributes if they exist\n",
    "                if edge_attr is not None:\n",
    "                    # Use random edge attributes similar to existing ones\n",
    "                    if edge_attr.size(0) > 0:\n",
    "                        rand_idx = random.randint(0, edge_attr.size(0) - 1)\n",
    "                        new_attr = edge_attr[rand_idx].clone()\n",
    "                        # Add some noise to attributes\n",
    "                        new_attr = new_attr * (0.9 + 0.2 * torch.rand_like(new_attr))\n",
    "                        new_attr = torch.stack([new_attr, new_attr])\n",
    "                        edge_attr = torch.cat([edge_attr, new_attr], dim=0)\n",
    "    \n",
    "    # If random probability < p_remove then remove edges\n",
    "    if random.random() < p_remove and edge_index.size(1) > 2:  # Ensure we have edges to remove\n",
    "        # Remove multiple edges\n",
    "        num_edges_to_remove = max(1, int(edge_index.size(1) * 0.05))  # Remove 5% of edges\n",
    "        \n",
    "        # For undirected graphs, ensure we don't disconnect the graph\n",
    "        # Create a simple connectivity check by counting unique nodes in edges\n",
    "        # This isn't a full connectivity check but helps preserve graph structure\n",
    "        num_unique_edges = edge_index.size(1) // 2\n",
    "        if num_unique_edges > num_edges_to_remove:\n",
    "            edges_to_remove = set(random.sample(range(num_unique_edges), num_edges_to_remove))\n",
    "            \n",
    "            # Create a mask to keep all edges except the selected ones and their reverse\n",
    "            mask = torch.ones(edge_index.size(1), dtype=torch.bool, device=edge_index.device)\n",
    "            for edge_idx in edges_to_remove:\n",
    "                mask[2*edge_idx] = False\n",
    "                mask[2*edge_idx+1] = False\n",
    "            \n",
    "            # E_aug ← E_aug \\ e_remove\n",
    "            edge_index = edge_index[:, mask]\n",
    "            if edge_attr is not None:\n",
    "                edge_attr = edge_attr[mask]\n",
    "    \n",
    "    # Update the data object with augmented edge index and attributes\n",
    "    data.edge_index = edge_index\n",
    "    if edge_attr is not None:\n",
    "        data.edge_attr = edge_attr\n",
    "    \n",
    "    return data\n",
    "\n",
    "class GraphAugmentation(object):\n",
    "    \"\"\"Combine multiple graph augmentation techniques\"\"\"\n",
    "    def __init__(self, p_edge=0.5):\n",
    "        self.p_edge = p_edge\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        # Apply edge augmentation with probability p_edge\n",
    "        if random.random() < self.p_edge:\n",
    "            data = edge_augmentation(data, p_add=0.1, p_remove=0.1)\n",
    "\n",
    "         \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:48.116336Z",
     "iopub.status.busy": "2025-05-08T12:59:48.116052Z",
     "iopub.status.idle": "2025-05-08T12:59:48.129641Z",
     "shell.execute_reply": "2025-05-08T12:59:48.128990Z",
     "shell.execute_reply.started": "2025-05-08T12:59:48.116315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# 2. IMPROVED DATA LOADING & AUGMENTATION #\n",
    "#################################\n",
    "\n",
    "class LeafGraphDataset(Dataset):\n",
    "    def __init__(self, root_dir, precomputed_dir=None, transform=None, use_precomputed=False):\n",
    "        super().__init__(root=None, transform=transform)\n",
    "        self.root_dir = root_dir\n",
    "        self.precomputed_dir = precomputed_dir\n",
    "        self.transform = transform\n",
    "        self.use_precomputed = use_precomputed\n",
    "        self.data_list = []\n",
    "        self.label_map = {}\n",
    "        self.class_samples = {}  # To track class balance\n",
    "        \n",
    "        # Process dataset\n",
    "        classes = sorted(os.listdir(root_dir))\n",
    "        for idx, cls in enumerate(classes):\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(cls_path):\n",
    "                continue\n",
    "                \n",
    "            self.label_map[cls] = idx\n",
    "            self.class_samples[idx] = 0  # Initialize counter\n",
    "            print(f\"Class {cls} -> Label {idx}\")\n",
    "            \n",
    "            if self.use_precomputed:\n",
    "                # Load precomputed graphs\n",
    "                precomputed_cls_path = os.path.join(precomputed_dir, cls)\n",
    "                if not os.path.exists(precomputed_cls_path):\n",
    "                    print(f\"Warning: Precomputed directory {precomputed_cls_path} not found\")\n",
    "                    continue\n",
    "                \n",
    "                graph_files = [f for f in os.listdir(precomputed_cls_path) if f.endswith('.pkl')]\n",
    "                for graph_file in graph_files:\n",
    "                    graph_path = os.path.join(precomputed_cls_path, graph_file)\n",
    "                    self.data_list.append((graph_path, idx, True))  # True indicates precomputed\n",
    "                    self.class_samples[idx] += 1\n",
    "            else:\n",
    "                # Use original images\n",
    "                img_files = [f for f in os.listdir(cls_path) \n",
    "                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                \n",
    "                for img_name in img_files:\n",
    "                    img_path = os.path.join(cls_path, img_name)\n",
    "                    self.data_list.append((img_path, idx, False))  # False indicates not precomputed\n",
    "                    self.class_samples[idx] += 1\n",
    "        \n",
    "        # Print class distribution\n",
    "        total_samples = len(self.data_list)\n",
    "        print(\"\\nClass distribution:\")\n",
    "        for cls, idx in self.label_map.items():\n",
    "            count = self.class_samples[idx]\n",
    "            pct = count / total_samples * 100\n",
    "            print(f\"  {cls}: {count} samples ({pct:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nLoaded {len(self.data_list)} {'graphs' if use_precomputed else 'images'} with {len(self.label_map)} classes\")\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        file_path, label, is_precomputed = self.data_list[idx]\n",
    "        \n",
    "        try:\n",
    "            if is_precomputed:\n",
    "                # Load precomputed graph\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    \n",
    "                # Unpack based on whether edge_attr was included in precomputation\n",
    "                if len(data) == 3:\n",
    "                    x, edge_index, edge_attr = data\n",
    "                else:\n",
    "                    x, edge_index = data\n",
    "                    # Create default edge attributes if not present\n",
    "                    num_edges = edge_index.shape[1]\n",
    "                    edge_attr = torch.ones((num_edges, 1), dtype=torch.float)\n",
    "            else:\n",
    "                # Process image on-the-fly\n",
    "                x, edge_index, edge_attr = preprocessing_image_to_graph(file_path)\n",
    "            \n",
    "            # Create PyG Data object\n",
    "            y = torch.tensor([label], dtype=torch.long)\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "            \n",
    "            # Apply transform if available\n",
    "            if self.transform is not None:\n",
    "                data = self.transform(data)\n",
    "                \n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            # Return a simple fallback data object\n",
    "            x = torch.ones((10, 10), dtype=torch.float)\n",
    "            edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "            edge_attr = torch.ones((4, 1), dtype=torch.float)\n",
    "            y = torch.tensor([label], dtype=torch.long)\n",
    "            return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.get(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight initialization**\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:48.131023Z",
     "iopub.status.busy": "2025-05-08T12:59:48.130797Z",
     "iopub.status.idle": "2025-05-08T12:59:48.140452Z",
     "shell.execute_reply": "2025-05-08T12:59:48.139875Z",
     "shell.execute_reply.started": "2025-05-08T12:59:48.131008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WeightInitialization(object):\n",
    "    \"\"\"Enhanced weight initialization for the model using He initialization\"\"\"\n",
    "    @staticmethod\n",
    "    def apply(model):\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                # He initialization using uniform distribution as per Equation 1\n",
    "                fan_in = m.in_features\n",
    "                bound = math.sqrt(6.0 / fan_in)\n",
    "                torch.nn.init.uniform_(m.weight, -bound, bound)\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "            \n",
    "            elif isinstance(m, GCNConv):\n",
    "                if hasattr(m, 'lin') and m.lin is not None:\n",
    "                    # For GCNConv, determine input features\n",
    "                    if hasattr(m.lin, 'in_features'):\n",
    "                        fan_in = m.lin.in_features\n",
    "                    else:\n",
    "                        # Fallback if in_features is not directly accessible\n",
    "                        fan_in = m.lin.weight.size(1)\n",
    "                    \n",
    "                    bound = math.sqrt(6.0 / fan_in)\n",
    "                    torch.nn.init.uniform_(m.lin.weight, -bound, bound)\n",
    "                    if m.lin.bias is not None:\n",
    "                        torch.nn.init.zeros_(m.lin.bias)\n",
    "            \n",
    "            elif isinstance(m, GATConv):\n",
    "                # Handle GAT source linear transformation\n",
    "                if hasattr(m, 'lin_src') and m.lin_src is not None:\n",
    "                    if hasattr(m.lin_src, 'weight') and m.lin_src.weight is not None:\n",
    "                        if hasattr(m.lin_src, 'in_features'):\n",
    "                            fan_in = m.lin_src.in_features\n",
    "                        else:\n",
    "                            # Fallback to weight shape\n",
    "                            fan_in = m.lin_src.weight.size(1)\n",
    "                        \n",
    "                        bound = math.sqrt(6.0 / fan_in)\n",
    "                        torch.nn.init.uniform_(m.lin_src.weight, -bound, bound)\n",
    "                        if m.lin_src.bias is not None:\n",
    "                            torch.nn.init.zeros_(m.lin_src.bias)\n",
    "                \n",
    "                # Handle GAT target linear transformation if present\n",
    "                if hasattr(m, 'lin_dst') and m.lin_dst is not None:\n",
    "                    if hasattr(m.lin_dst, 'weight') and m.lin_dst.weight is not None:\n",
    "                        if hasattr(m.lin_dst, 'in_features'):\n",
    "                            fan_in = m.lin_dst.in_features\n",
    "                        else:\n",
    "                            fan_in = m.lin_dst.weight.size(1)\n",
    "                        \n",
    "                        bound = math.sqrt(6.0 / fan_in)\n",
    "                        torch.nn.init.uniform_(m.lin_dst.weight, -bound, bound)\n",
    "                        if m.lin_dst.bias is not None:\n",
    "                            torch.nn.init.zeros_(m.lin_dst.bias)\n",
    "                \n",
    "                # Initialize attention weights if present\n",
    "                if hasattr(m, 'att') and m.att is not None:\n",
    "                    if hasattr(m, 'heads'):\n",
    "                        # For multi-head attention, use head dimension\n",
    "                        fan_in = m.heads\n",
    "                    else:\n",
    "                        fan_in = 1\n",
    "                    \n",
    "                    bound = math.sqrt(6.0 / fan_in)\n",
    "                    torch.nn.init.uniform_(m.att, -bound, bound)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Model Architechture**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T15:30:42.095242Z",
     "iopub.status.busy": "2025-05-08T15:30:42.094694Z",
     "iopub.status.idle": "2025-05-08T15:30:42.112319Z",
     "shell.execute_reply": "2025-05-08T15:30:42.111510Z",
     "shell.execute_reply.started": "2025-05-08T15:30:42.095216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#######################################\n",
    "# GCN Block with number_of_layers = 2 #\n",
    "#######################################\n",
    "class GraphConvolutionBlock(torch.nn.Module):\n",
    "    \"\"\"Enhanced Graph Convolutional block with residual connections\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, use_edge_attr=True):\n",
    "        super(GraphConvolutionBlock, self).__init__()\n",
    "        self.use_edge_attr = use_edge_attr\n",
    "\n",
    "        # GCN layers\n",
    "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        identity = x\n",
    "\n",
    "        # First GCN layer\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        # Second GCN layer\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "#######################################\n",
    "# GAT Block with number_of_layers = 2 #\n",
    "#######################################\n",
    "\n",
    "\n",
    "class GraphAttentionBlock(torch.nn.Module):\n",
    "    \"\"\"Enhanced Graph Attention block with residual connections\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, heads=2, use_edge_attr=True):\n",
    "        super(GraphAttentionBlock, self).__init__()\n",
    "        self.use_edge_attr = use_edge_attr\n",
    "\n",
    "        # GAT layers\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels // heads, heads=heads)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.gat2 = GATConv(hidden_channels, hidden_channels // heads, heads=heads)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        identity = x\n",
    "\n",
    "        # First GAT layer\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        # Second GAT layer\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "###################\n",
    "# Classifer layer #\n",
    "###################\n",
    "\n",
    "class EnhancedClassifier(torch.nn.Module):\n",
    "    \"\"\"Enhanced Classification layer with multi-scale features\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
    "        super(EnhancedClassifier, self).__init__()\n",
    "        \n",
    "        # First fully-connected layer\n",
    "        self.fc1 = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        \n",
    "        # Second fully-connected layer\n",
    "        self.fc2 = torch.nn.Linear(hidden_channels, hidden_channels // 2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels // 2)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = torch.nn.Linear(hidden_channels // 2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        # Second layer\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        # Output layer\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "###############\n",
    "# Final Model #\n",
    "###############\n",
    "\n",
    "class HybridGCNGATModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced hybrid model combining GCN and GAT layers with residual connections\n",
    "    for plant disease classification from graph representations\n",
    "    \"\"\"\n",
    "    def __init__(self, num_node_features, num_classes, hidden_channels=256, \n",
    "                 use_edge_attr=True, gcn_layers=1, gat_layers=1):\n",
    "        super(HybridGCNGATModel, self).__init__()\n",
    "\n",
    "        self.use_edge_attr = use_edge_attr\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Feature transformation layer\n",
    "        self.feature_transform = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_node_features, hidden_channels),\n",
    "            torch.nn.BatchNorm1d(hidden_channels),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        # GCN blocks\n",
    "        self.gcn_blocks = torch.nn.ModuleList()\n",
    "        for i in range(gcn_layers):\n",
    "            self.gcn_blocks.append(\n",
    "                GraphConvolutionBlock(hidden_channels, hidden_channels, use_edge_attr)\n",
    "            )\n",
    "            \n",
    "        # GAT blocks\n",
    "        self.gat_blocks = torch.nn.ModuleList()\n",
    "        for i in range(gat_layers):\n",
    "            self.gat_blocks.append(\n",
    "                GraphAttentionBlock(hidden_channels, hidden_channels, heads=2, use_edge_attr=use_edge_attr)\n",
    "            )\n",
    "        \n",
    "        # Global pooling\n",
    "        self.global_pool = lambda x, batch: torch.cat([\n",
    "            global_mean_pool(x, batch),\n",
    "            global_max_pool(x, batch)\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Final classifier\n",
    "        pool_size = hidden_channels * 2  # Mean + Max pooling\n",
    "        self.classifier = EnhancedClassifier(pool_size, hidden_channels, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        WeightInitialization.apply(self)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        edge_attr = data.edge_attr if hasattr(data, 'edge_attr') and self.use_edge_attr else None\n",
    "        \n",
    "        # Feature transformation\n",
    "        x = self.feature_transform(x)\n",
    "        \n",
    "        # Apply GCN blocks\n",
    "        for gcn_block in self.gcn_blocks:\n",
    "            x = gcn_block(x, edge_index, edge_attr)\n",
    "        \n",
    "        # Apply GAT blocks\n",
    "        for gat_block in self.gat_blocks:\n",
    "            x = gat_block(x, edge_index, edge_attr)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = self.global_pool(x, batch)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def summary(self):\n",
    "        print(\"========== Hybrid GCN GAT Model Summary ==========\")\n",
    "        print(f\"Input features: {self.num_node_features}\")\n",
    "        print(f\"Hidden channels: {self.gcn_blocks[0].gcn1.in_channels if self.gcn_blocks else 'N/A'} → {self.gcn_blocks[0].gcn1.out_channels if self.gcn_blocks else 'N/A'}\")\n",
    "        print(f\"Use edge attributes: {self.use_edge_attr}\")\n",
    "        print(f\"GCN layers: {len(self.gcn_blocks)}\")\n",
    "        print(f\"GAT layers: {len(self.gat_blocks)}\")\n",
    "        print(f\"Pooling type: Global Mean + Max\")\n",
    "        print(f\"Classifier input size: {self.classifier.fc1.in_features}\")\n",
    "        print(f\"Number of classes: {self.num_classes}\")\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lossfunciton - Crossentropy**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:48.215696Z",
     "iopub.status.busy": "2025-05-08T12:59:48.215445Z",
     "iopub.status.idle": "2025-05-08T12:59:48.221673Z",
     "shell.execute_reply": "2025-05-08T12:59:48.221054Z",
     "shell.execute_reply.started": "2025-05-08T12:59:48.215668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Cross-Entropy Loss implementation following the mathematical formula:\n",
    "    Cross-Entropy Loss = -∑∑y_ij log(p_ij)\n",
    "    \n",
    "    Where:\n",
    "    - y represents the true distribution of the labels\n",
    "    - p represents the predicted distribution of the labels\n",
    "    - i ranges from 1 to N (number of samples)\n",
    "    - j ranges from 1 to C (number of classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction='mean', epsilon=1e-12):\n",
    "        super(CrossEntropyLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.epsilon = epsilon  # Small constant to avoid log(0)\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Raw logits from the model, shape (N, C)\n",
    "            targets (torch.Tensor): Ground truth class indices, shape (N,)\n",
    "                                   or one-hot encoded targets, shape (N, C)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Calculated cross-entropy loss\n",
    "        \"\"\"\n",
    "        # Get batch size and number of classes\n",
    "        N = inputs.size(0)\n",
    "        C = inputs.size(1)\n",
    "        \n",
    "        # Convert logits to probabilities using softmax\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        \n",
    "        # Add small epsilon to avoid log(0)\n",
    "        probs = probs + self.epsilon\n",
    "        \n",
    "        # If targets are class indices, convert to one-hot encoding\n",
    "        if targets.dim() == 1:\n",
    "            targets_one_hot = torch.zeros_like(probs)\n",
    "            targets_one_hot.scatter_(1, targets.unsqueeze(1), 1)\n",
    "        else:\n",
    "            targets_one_hot = targets\n",
    "        \n",
    "        # Calculate cross-entropy loss according to the formula\n",
    "        # -∑∑y_ij log(p_ij)\n",
    "        log_probs = torch.log(probs)\n",
    "        loss = -torch.sum(targets_one_hot * log_probs, dim=1)\n",
    "        \n",
    "        # Apply reduction\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:  # 'none'\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train - Evaluation function**\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:59:48.222749Z",
     "iopub.status.busy": "2025-05-08T12:59:48.222471Z",
     "iopub.status.idle": "2025-05-08T12:59:48.239829Z",
     "shell.execute_reply": "2025-05-08T12:59:48.239312Z",
     "shell.execute_reply.started": "2025-05-08T12:59:48.222727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# 5. TRAINING UTILITIES AND EVALUATION #\n",
    "#######################################\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    for data in tqdm(loader, desc=\"Training\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, data.y.squeeze())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y.squeeze()).sum())\n",
    "        total += data.num_graphs\n",
    "    \n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    \"\"\"Evaluate model test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=\"Evaluating\"):\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(data)\n",
    "            loss = loss_fn(out, data.y.squeeze())\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += int((pred == data.y.squeeze()).sum())\n",
    "            total += data.num_graphs\n",
    "            \n",
    "            # Store predictions and targets for confusion matrix\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_targets.append(data.y.squeeze().cpu())\n",
    "    \n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    # Combine predictions and targets\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    \n",
    "    return avg_loss, accuracy, all_preds, all_targets\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, optimizer, loss_fn, \n",
    "                device, num_epochs=100, checkpoint_path='best_model.pt'):\n",
    "    \"\"\"\n",
    "    Train model with early stopping and learning rate scheduling\n",
    "    \"\"\"\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    no_improve_count = 0\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train one epoch\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "       \n",
    "        # Save the model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_acc': train_acc,\n",
    "            'train_loss': train_loss\n",
    "                    }, checkpoint_path)\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training loss and accuracy on the same axis with dual y-axes\"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot training loss (left y-axis)\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color=color)\n",
    "    ax1.plot(history['train_loss'], label='Train Loss', color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create a second y-axis for accuracy\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:orange'\n",
    "    ax2.set_ylabel('Accuracy', color=color)\n",
    "    ax2.plot(history['train_acc'], label='Train Accuracy', color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Title and layout\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for visualization\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create a confusion matrix display\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, label_map=None):\n",
    "    \"\"\"\n",
    "    Complete model evaluation including confusion matrix and class-wise metrics\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Lists to store predictions and targets\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # Evaluation loop\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_targets.append(data.y.squeeze().cpu())\n",
    "    \n",
    "    # Combine all predictions and targets\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generate classification report\n",
    "    if label_map:\n",
    "        # Convert numeric labels to class names\n",
    "        class_names = {v: k for k, v in label_map.items()}\n",
    "        target_names = [class_names[i] for i in range(len(class_names))]\n",
    "        \n",
    "        # Print classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(all_targets, all_preds, target_names=target_names))\n",
    "        \n",
    "        # Calculate class-wise metrics\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(all_targets, all_preds)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(all_targets, all_preds, target_names)\n",
    "    else:\n",
    "        # Print classification report with numeric labels\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(all_targets, all_preds))\n",
    "    \n",
    "    # Return metrics\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': all_preds,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main Function**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:18:48.227930Z",
     "iopub.status.busy": "2025-05-08T18:18:48.227172Z",
     "iopub.status.idle": "2025-05-08T18:26:47.513443Z",
     "shell.execute_reply": "2025-05-08T18:26:47.512867Z",
     "shell.execute_reply.started": "2025-05-08T18:18:48.227902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main(dataset_root, output_dir, precomputed_dir=None, batch_size=32, hidden_channels=512,\n",
    "         learning_rate=0.001, num_epochs=100, use_precomputed=True, precompute_only=False):\n",
    "    \"\"\"\n",
    "    Main function to run the entire pipeline\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 1. Dataset Preparation\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Check if dataset is already split\n",
    "    if not os.path.exists(os.path.join(output_dir, 'train')) or \\\n",
    "       not os.path.exists(os.path.join(output_dir, 'test')):\n",
    "        print(\"Splitting dataset into train and test sets...\")\n",
    "        split_dataset(dataset_root, output_dir)\n",
    "    \n",
    "    # 2. Precompute graphs if needed\n",
    "    if use_precomputed and precomputed_dir:\n",
    "        precomputation_needed = False\n",
    "        \n",
    "        # Check if precomputed files exist\n",
    "        for split in ['train', 'test']:\n",
    "            split_precomputed_dir = os.path.join(precomputed_dir, split)\n",
    "            if not os.path.exists(split_precomputed_dir) or len(os.listdir(split_precomputed_dir)) == 0:\n",
    "                precomputation_needed = True\n",
    "                break\n",
    "        \n",
    "        if precomputation_needed:\n",
    "            print(\"Precomputed graphs not found. Precomputing now...\")\n",
    "            if not os.path.exists(precomputed_dir):\n",
    "                os.makedirs(precomputed_dir)\n",
    "                \n",
    "            for split in ['train', 'test']:\n",
    "                split_dir = os.path.join(output_dir, split)\n",
    "                split_precomputed_dir = os.path.join(precomputed_dir, split)\n",
    "                \n",
    "                if not os.path.exists(split_precomputed_dir):\n",
    "                    os.makedirs(split_precomputed_dir)\n",
    "                \n",
    "                # Only precompute if directory is empty\n",
    "                if len(os.listdir(split_precomputed_dir)) == 0:\n",
    "                    print(f\"Processing {split} split...\")\n",
    "                    save_precomputed_graphs(split_dir, split_precomputed_dir)\n",
    "                else:\n",
    "                    print(f\"Precomputed graphs for {split} already exist. Skipping.\")\n",
    "        else:\n",
    "            print(\"Using existing precomputed graphs.\")\n",
    "    \n",
    "    \n",
    "    # Exit if only precomputing\n",
    "    if precompute_only:\n",
    "        print(\"Precomputation completed. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # 3. Create datasets\n",
    "    print(\"Creating datasets...\")\n",
    "    \n",
    "    # Data augmentation for training\n",
    "    transform_train = GraphAugmentation(p_edge=0.5)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = LeafGraphDataset(\n",
    "        os.path.join(output_dir, 'train'),\n",
    "        os.path.join(precomputed_dir, 'train') if precomputed_dir else None,\n",
    "        transform=transform_train,\n",
    "        use_precomputed=use_precomputed\n",
    "    )\n",
    "    \n",
    "    test_dataset = LeafGraphDataset(\n",
    "        os.path.join(output_dir, 'test'),\n",
    "        os.path.join(precomputed_dir, 'test') if precomputed_dir else None,\n",
    "        transform=None,\n",
    "        use_precomputed=use_precomputed\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    num_classes = len(train_dataset.label_map)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # 4. Create model\n",
    "    sample_data = train_dataset[0]\n",
    "    num_node_features = sample_data.x.size(1)\n",
    "    print(f\"Number of node features: {num_node_features}\")\n",
    "    \n",
    "    # Define model\n",
    "    model = HybridGCNGATModel(\n",
    "        num_node_features=num_node_features,\n",
    "        num_classes = num_classes,\n",
    "        hidden_channels=hidden_channels, \n",
    "        use_edge_attr=True,\n",
    "        gcn_layers=1,            \n",
    "        gat_layers=1          \n",
    "    ).to(device)\n",
    "\n",
    "    \n",
    "    print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    # 5. Set up training\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Use mixed loss for handling class imbalance\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    \n",
    "    # 6. Train model\n",
    "    model, history = train_model(\n",
    "        model, train_loader, optimizer, loss_fn,\n",
    "        device, num_epochs=num_epochs, checkpoint_path=os.path.join(output_dir, 'best_model.pt')\n",
    "    )\n",
    "    \n",
    "    # 7. Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # 8. Evaluate model on test set\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "    eval_results = evaluate_model(model, test_loader, device, train_dataset.label_map)\n",
    "    \n",
    "    print(f\"✅ Model evaluation completed with test accuracy: {eval_results['accuracy']:.4f}\")\n",
    "    \n",
    "    return model, train_dataset.label_map, eval_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    # Define command-line arguments\n",
    "    \"\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Train GCN+GAT hybrid model for leaf disease classification\")\n",
    "    parser.add_argument('--dataset_root', type=str, required=True, help='Path to raw leaf dataset')\n",
    "    parser.add_argument('--output_dir', type=str, required=True, help='Path to store processed data and checkpoints')\n",
    "    parser.add_argument('--precomputed_dir', type=str, default=None, help='Path to store/load precomputed graphs')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for training')\n",
    "    parser.add_argument('--hidden_channels', type=int, default=512, help='Hidden layer dimension')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001, help='Learning rate')\n",
    "    parser.add_argument('--num_epochs', type=int, default=100, help='Number of training epochs')\n",
    "    parser.add_argument('--use_precomputed', action='store_true', help='Use precomputed graphs')\n",
    "    parser.add_argument('--precompute_only', action='store_true', help='Only precompute graphs then exit')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "        # Run main pipeline\n",
    "    model, label_map, eval_results = main(\n",
    "        dataset_root=args.dataset_root,\n",
    "        output_dir=args.output_dir,\n",
    "        precomputed_dir=args.precomputed_dir,\n",
    "        batch_size=args.batch_size,\n",
    "        hidden_channels=args.hidden_channels,\n",
    "        learning_rate=args.learning_rate,\n",
    "        num_epochs=args.num_epochs,\n",
    "        use_precomputed=args.use_precomputed,\n",
    "        precompute_only=args.precompute_only\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_root = '/kaggle/working/your_Dataset_dir_path' # change your data dir path here!!!!!\n",
    "\n",
    "    # Output dir contains your split dataset and your trained weights model\n",
    "    output_dir = '/kaggle/working/your_output_dir_path' # change your output dir here!!!!!!!\n",
    "\n",
    "    # Precomputed dir will contain data in graph format \n",
    "    precomputed_dir = '/kaggle/working/your_precomputed_dir_path'\n",
    "    \n",
    "    main(\n",
    "        dataset_root=dataset_root,\n",
    "        output_dir=output_dir,\n",
    "        precomputed_dir=precomputed_dir,\n",
    "        batch_size=32,\n",
    "        hidden_channels=512,\n",
    "        learning_rate=0.001,\n",
    "        num_epochs=100,\n",
    "        use_precomputed=True,\n",
    "        precompute_only=False\n",
    "    )    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1125279,
     "sourceId": 1888915,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1240033,
     "sourceId": 2068940,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4320051,
     "sourceId": 7424766,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
